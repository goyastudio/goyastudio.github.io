---
---

@mics{hong2024deepjeb,
  title={DeepJEB: 3D Deep Learning-based Synthetic Jet Engine Bracket Dataset},
  author={Hong*, Seongjun and Kwon*, Yongmin and Shin, Dongju and Park, Jangseop and Kang, Namwoo},
  year={2024},
  eprint={2406.09047},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  pdf={2406.09047v2.pdf},
  arxiv={2406.09047},
  preview = {DeepJEB_abstract.png},
  abstract={Recent advances in artificial intelligence (AI) have impacted various fields, 
  including mechanical engineering. However, the development of diverse, high-quality datasets 
  for structural analysis remains a challenge. Traditional datasets, like the jet engine bracket dataset, 
  are limited by small sample sizes, hindering the creation of robust surrogate models. 
  This study introduces the DeepJEB dataset, generated through deep generative models and automated simulation pipelines, 
  to address these limitations. DeepJEB offers comprehensive 3D geometries and corresponding structural analysis data. 
  Key experiments validated its effectiveness, showing significant improvements in surrogate model performance. 
  Models trained on DeepJEB achieved up to a 23% increase in the coefficient of determination and over a 70% reduction 
  in mean absolute percentage error (MAPE) compared to those trained on traditional datasets. 
  These results underscore the superior generalization capabilities of DeepJEB. By supporting advanced modeling techniques, 
  such as graph neural networks (GNNs) and convolutional neural networks (CNNs), DeepJEB enables more accurate predictions 
  in structural performance. The DeepJEB dataset is publicly accessible at: 
  <a href="https://www.narnia.ai/dataset"> this URL</a>.},
  selected={true},

}

@misc{kim2024deep,
      title={Deep Generative Design for Mass Production}, 
      author={Jihoon Kim* and Yongmin Kwon* and Namwoo Kang},
      year={2024},
      eprint={2403.12098},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      pdf={2403.12098v1.pdf},
      arxiv={2403.12098},
      preview={deep-generative-design-for-mass-production.png},
      abstract={Generative Design (GD) has evolved as a transformative design approach, employing advanced algorithms and AI
      to create diverse and innovative solutions beyond traditional constraints. Despite its success, GD faces significant
      challenges regarding the manufacturability of complex designs, often necessitating extensive manual modifications
      due to limitations in standard manufacturing processes and the reliance on additive manufacturing, which is not ideal
      for mass production. Our research introduces an innovative framework addressing these manufacturability concerns
      by integrating constraints pertinent to die casting and injection molding into GD, through the utilization of 2D depth
      images. This method simplifies intricate 3D geometries into manufacturable profiles, removing unfeasible features
      such as non-manufacturable overhangs and allowing for the direct consideration of essential manufacturing aspects
      like thickness and rib design. Consequently, designs previously unsuitable for mass production are transformed into
      viable solutions. We further enhance this approach by adopting an advanced 2D generative model, which offer a more
      efficient alternative to traditional 3D shape generation methods. Our results substantiate the efficacy of this framework,
      demonstrating the production of innovative, and, importantly, manufacturable designs. This shift towards integrating
      practical manufacturing considerations into GD represents a pivotal advancement, transitioning from purely inspirational 
      concepts to actionable, production-ready solutions. Our findings underscore usefulness and potential of GD
      for broader industry adoption, marking a significant step forward in aligning GD with the demands of manufacturing
      challenges.},
      selected={true},
}


@misc{kwon2025threedimensionaldeepshapeoptimization,
      title={Three-dimensional Deep Shape Optimization with a Limited Dataset}, 
      author={Yongmin Kwon* and Namwoo Kang},
      year={2025},
      eprint={2506.12326},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      pdf={2506.12326_.pdf},
      arxiv={2506.12326},
      preview={overall_framework.jpg},
      abstract={Generative models have attracted considerable attention for their ability to produce novel shapes. 
      However, their application in mechanical design remains constrained due to the limited size and variability of available datasets. 
      This study proposes a deep learning-based optimization framework specifically tailored for shape optimization with limited datasets, 
      leveraging positional encoding and a Lipschitz regularization term to robustly learn geometric characteristics and maintain a meaningful latent space. 
      Through extensive experiments, the proposed approach demonstrates robustness, generalizability and effectiveness in addressing typical limitations of conventional optimization frameworks.
      The validity of the methodology is confirmed through multi-objective shape optimization experiments conducted on diverse three-dimensional datasets, including wheels and cars, 
      highlighting the model's versatility in producing practical and high-quality design outcomes even under data-constrained conditions.},
      selected={true},
}
